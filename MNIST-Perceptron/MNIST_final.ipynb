{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:04.565983Z",
     "start_time": "2024-10-20T16:28:00.479984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torch\n",
    "\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(root='./data',\n",
    "                    transform= lambda x: np.array(x).flatten(),\n",
    "                    download=True,\n",
    "                    train=is_train)\n",
    "    mnist_data= []\n",
    "    mnist_labels= []\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append(label)\n",
    "\n",
    "    return mnist_data, mnist_labels\n",
    "\n",
    "def process_data(mnist_data, mnist_labels):\n",
    "    mnist_data = np.array(mnist_data).reshape(-1, 784)\n",
    "    mnist_labels = np.array(mnist_labels).reshape(-1, 1)\n",
    "\n",
    "    procesed_mnist_labels = []\n",
    "    for mnist_label in mnist_labels:\n",
    "        a = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "        value = mnist_label[0]\n",
    "        a[value] = 1\n",
    "        procesed_mnist_labels.append(np.array(a))\n",
    "\n",
    "    mnist_data = mnist_data / 255\n",
    "    return mnist_data, procesed_mnist_labels"
   ],
   "id": "8e8d8268e0d3e58c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:04.619610Z",
     "start_time": "2024-10-20T16:28:04.611543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Split data into batches\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def split_in_batches(data, labels, batch_size=100):\n",
    "    dataset = TensorDataset(torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    batched_data = []\n",
    "    batched_labels = []\n",
    "\n",
    "    for batch_data, batch_labels in loader:\n",
    "        batched_data.append(batch_data.numpy())\n",
    "        batched_labels.append(batch_labels.numpy())\n",
    "    return batched_data, batched_labels"
   ],
   "id": "95542551f2625ee7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:04.681858Z",
     "start_time": "2024-10-20T16:28:04.672666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        self.weights = np.random.randn(input_size, num_classes) * 0.01\n",
    "        self.bias = np.zeros((1, num_classes))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.softmax(z)\n",
    "\n",
    "    def compute_loss(self, Y_pred, Y_true):\n",
    "        m = Y_true.shape[0]\n",
    "        loss = -np.sum(Y_true * np.log(Y_pred + 1e-9)) / m\n",
    "        return loss\n",
    "\n",
    "    def backward(self, X, Y_pred, Y_true, learning_rate):\n",
    "        m = X.shape[0] # number of examples\n",
    "        dz = Y_pred - Y_true  # error term\n",
    "        dw = np.dot(X.T, dz) / m  # gradient for weights\n",
    "        db = np.sum(dz, axis=0, keepdims=True) / m  # gradient for biases\n",
    "\n",
    "        self.weights -= learning_rate * dw\n",
    "        self.bias -= learning_rate * db"
   ],
   "id": "61fd26140b3f6b75",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:06.446694Z",
     "start_time": "2024-10-20T16:28:06.439928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Forward pass (logits computation)\n",
    "def train_epoch(process_train_X, process_train_Y, perceptron, learning_rate):\n",
    "    batched_train_data, batched_train_labels = split_in_batches(process_train_X, process_train_Y)\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_data, batch_labels in zip(batched_train_data, batched_train_labels):\n",
    "        probabilities = perceptron.forward(batch_data)\n",
    "        loss = perceptron.compute_loss(probabilities, batch_labels)\n",
    "        perceptron.backward(batch_data, probabilities, batch_labels, learning_rate)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    epoch_loss /= len(batched_train_data)\n",
    "    print(f\"Epoch loss: {epoch_loss}\")\n",
    "\n",
    "    return epoch_loss\n"
   ],
   "id": "e1b373eaad763eb8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:08.112953Z",
     "start_time": "2024-10-20T16:28:08.105233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_accuracy(data, labels, perceptron):\n",
    "    probabilities = perceptron.forward(data)\n",
    "    predicted_classes = np.argmax(probabilities, axis=1) # get the index of the highest probability\n",
    "    true_classes = np.argmax(labels, axis=1)   # get the index of the true class\n",
    "    correct_predictions = np.sum(predicted_classes == true_classes) # count how many predictions were correct\n",
    "    accuracy = correct_predictions / len(labels) * 100 \n",
    "    return accuracy"
   ],
   "id": "ca8ef1b22f920623",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:18.368574Z",
     "start_time": "2024-10-20T16:28:11.886685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_X, train_Y = download_mnist(True)\n",
    "test_x, test_y = download_mnist(False)\n",
    "\n",
    "process_train_X, process_train_Y = process_data(train_X, train_Y)\n",
    "process_test_x, process_test_y = process_data(test_x, test_y)\n",
    "\n",
    "# just first time\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "learning_rate = 0.1\n",
    "perceptron = Perceptron(input_size, num_classes)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    epoch_loss = train_epoch(process_train_X, process_train_Y, perceptron, learning_rate)\n",
    "    print(f\"Loss after epoch {epoch + 1}: {epoch_loss}\")\n",
    "\n",
    "train_accuracy = calculate_accuracy(process_train_X, process_train_Y, perceptron)\n",
    "print(f\"Train Accuracy: {train_accuracy}%\")"
   ],
   "id": "c39e6c11e3b6b7ed",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:06:23.219642Z",
     "start_time": "2024-10-20T16:06:23.211429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model to a file\n",
    "import pickle\n",
    "def save_model(perceptron, filename='perceptron_model.pkl'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        # we serialize the model data (weights and bias) into a file\n",
    "        pickle.dump({'weights': perceptron.weights, 'bias': perceptron.bias}, f)\n",
    "\n",
    "# Save the model after training\n",
    "save_model(perceptron)"
   ],
   "id": "db38eb6a9530a0a",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:25.515448Z",
     "start_time": "2024-10-20T16:28:25.509028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model from a file\n",
    "def load_model(filename='perceptron_model.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    perceptron = Perceptron(input_size, num_classes)\n",
    "    perceptron.weights = model_data['weights']\n",
    "    perceptron.bias = model_data['bias']\n",
    "    return perceptron"
   ],
   "id": "6650dbd0e84947f5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:26.717669Z",
     "start_time": "2024-10-20T16:28:26.710621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "learning_rate = 0.1\n",
    "# perceptron = Perceptron(input_size, num_classes)\n",
    "\n",
    "perceptron=load_model()"
   ],
   "id": "c306d4b510292a4a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:28:36.785633Z",
     "start_time": "2024-10-20T16:28:36.750520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test accuracy on validation data\n",
    "validation_accuracy = calculate_accuracy(process_test_x, process_test_y, perceptron)\n",
    "print(f\"Validation Accuracy: {validation_accuracy}%\")"
   ],
   "id": "b26cbb8409bfe79e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 92.52%\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:23:28.488283Z",
     "start_time": "2024-10-20T16:23:24.290115Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install tensorboard",
   "id": "461b201578b12695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (1.67.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (2.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (5.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (74.1.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:30:39.448120Z",
     "start_time": "2024-10-20T16:30:39.407763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Select one image for each label\n",
    "selected_images = []\n",
    "selected_labels = []\n",
    "for i in range(10):\n",
    "    for img, lbl in zip(process_train_X, process_train_Y):\n",
    "        if np.argmax(lbl) == i:\n",
    "            selected_images.append(img)\n",
    "            selected_labels.append(lbl)\n",
    "            break\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "data_tensor = torch.tensor(selected_images, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(selected_labels, dtype=torch.float32)\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter('runs/perceptron_experiment_labels')\n",
    "\n",
    "# Add data to TensorBoard\n",
    "writer.add_embedding(data_tensor, metadata=labels_tensor.argmax(dim=1), label_img=data_tensor.view(-1, 1, 28, 28))\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ],
   "id": "652ad655d52813f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Documents\\Facultate\\Anul3\\Sem1\\RN\\MNIST-Perceptron\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T16:30:03.062373Z",
     "start_time": "2024-10-20T16:30:02.008907Z"
    }
   },
   "cell_type": "code",
   "source": "%pip tensorboard --logdir=runs",
   "id": "29ac7034fcb2acd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"tensorboard\"\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
